{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 8\n",
    "\n",
    "## Name: [TODO]\n",
    "\n",
    "## Link to your PS8 github repo: [TODO]\n",
    "\n",
    "### Problem 0 \n",
    "\n",
    "-2 points for every missing green OK sign. \n",
    "\n",
    "Make sure you are in the DATA1030 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from packaging.version import parse as Version\n",
    "from platform import python_version\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.12.10 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == Version(min_ver):\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))    \n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(python_version())\n",
    "\n",
    "if pyversion >= Version(\"3.12.10\"):\n",
    "    print(OK, \"Python version is %s\" % pyversion)\n",
    "elif pyversion < Version(\"3.12.10\"):\n",
    "    print(FAIL, \"Python version 3.12.10 is required,\"\n",
    "                \" but %s is installed.\" % pyversion)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % pyversion)\n",
    "\n",
    "    \n",
    "print()\n",
    "requirements = {'numpy': \"2.2.5\", 'matplotlib': \"3.10.1\",'sklearn': \"1.6.1\", \n",
    "                'pandas': \"2.2.3\",'xgboost': \"3.0.0\", 'shap': \"0.47.2\", \n",
    "                'polars': \"1.27.1\", 'seaborn': \"0.13.2\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "One ML algorithm we didn't cover during class is the nearest neighbor algorithm. The principle behind nearest neighbors is to base your prediction for a given point on the true labels of a predefined number of training samples closest to that point in the feature space. The predicted label is some sort of average of the true labels of the nearest neighbors. The number of nearest neighbors is a user-defined constant (k-nearest neighbor learning) which is one of the hyperparameters you'll need to tune. \n",
    "\n",
    "The challenge in this technique is the distance metric. How do you measure the distance between two points in the feature space? This is non-trivial question because usually different continuous features have different units and order of magnitudes, some features are one-hot-encoded, some features are ordinal. The key to successfully apply this method is usually to create a custom distance metric tailored to your dataset. However the standard Euclidean (geometric) distance is often used after the features are standard scaled.\n",
    "\n",
    "**(This is not necessary to know, but is still interesting)** The nearest-neighbor algorithm is unique because there is no model to train. The algorithm merely stores the training data in memory, and then checks which training points are closest to a given prediction point. This makes the nearest-neighbor algorithm train in O(1) time, but predict in O(n) time (with n referring to the number of **training** points, not testing). Generally, this is the opposite of what we want in an ML model -- it's much better to spend time precomputing than it is to spend time while predicting. Regardless, nearest-neighbors is still a very useful algorithm in some circumstances!\n",
    "\n",
    "Read more about this method [here](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification) and [here](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1a (10 points)\n",
    "\n",
    "In this problem, we will implement nearest neighbor regression. Read the manual of KNeighborsRegressor. Let's study how the `n_neighbors` parameter impacts the prediction.\n",
    "\n",
    "Please recreate the toy regression dataset from the lecture notes (Lecture 16, SVM regression) with n_samples = 30. Split the data into train and validation (70-30). Train models with n_neighbors = 1 to 10. Plot the train and validation scores using an evaluation metric of your choice as a function of n_neighbors.\n",
    "\n",
    "Next, visualize the models by creating more plots that display the train/val points with different colors, the true function, and the model predictions for the various n_neighbors values. Use trained models with n_neighbors = [1,3,10,30]. You will encounter an error message. Why? How do you fix it? Explain in a paragraph!\n",
    "\n",
    "Answer the following questions and explain your answer. \n",
    "   - What `n_neighbors` value produces a high bias (low variance) model? What `n_neighbors` value produces a high variance (low bias) model? How do overfitting and underfitting show up in the models?\n",
    "   - How does the model behave with respect to outliers?\n",
    "   - Explain why the model prediction is a step function and how this step function differs from a decision tree step function!\n",
    "\n",
    "Based on the manual, what other parameter has a strong influence on the predictions? Prepare another figure to prove your point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your explanation here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1b (5 points)\n",
    "\n",
    "Next, we'll implement the nearest neighbors algorithm for a classification problem! Please import KNeighborsClassifier and read the manual. Let's study how the `n_neighbors` parameters impact the prediction.\n",
    "\n",
    "Please recreate the toy classification dataset from the lecture notes (Lecture 16, SVM classification, make_moons dataset). \n",
    "\n",
    "Prepare a plot that shows predictions for n_neighbors = 1, 10, 30, and 100. Prepare the plots yourself in the notebook using matplotlib or seaborn.\n",
    "\n",
    "Explain in a paragraph when KNeighborsClassifier underfits and overfits. You can either make an argument based on the figures you prepared or you can split the dataset to train/val (70-30), train models, calculate the train and validation scores using an evaluation metric of your choice, and plot the scores. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your explanation here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Let's play around with more algorithms! In this problem, you will work with the diabetes dataset and try different ML algorithms to figure out which one is the best. Whenever you work with a new dataset, you want to try as many algorithms on it as possible because you can't know in advance which algorithm (and hyperparameters) will be the best.\n",
    "\n",
    "Generally you need to decide five things when you build an ML pipeline:\n",
    "- your splitting strategy\n",
    "- how to preprocess the data\n",
    "- what evaluation metric you'll use\n",
    "- what ML algorithms you will try\n",
    "- what paramater grid you should use for each ML algorithm\n",
    "\n",
    "You'll write a function in problem 2a that takes a preprocessor, an ML algorithm, and its corresponding parameter grid as inputs and it will calculate test scores and return the best models. The splitting strategy and the evaluation metric are not inputs to this function but predefined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2a (15 points)\n",
    "\n",
    "Write a function which takes the unprocessed feature matrix, target variable, a preprocessor (ColumnTransformer), an initialized ML algorithm, and a corresponding parameter grid as inputs. Do the following inside the function:\n",
    " 1. split the data to other and test (80-20) and then use KFold with 4 folds\n",
    " 2. preprocess the data and perform cross validation (I recommend you use GridSearchCV)\n",
    " 3. Finally, calculate the test score. Use RMSE as your evaluation metric. \n",
    " \n",
    " Repeat this 10 times for 10 different random states, and the function should return the 10 best models and the 10 test scores. Returning multiple models and test scores ensures that a machine learning model works similarly despite different random states. \n",
    " \n",
    " The skeleton of the function is provided for convenince.\n",
    "\n",
    "The function name contains the splitting strategy and the evaluation metric (i.e., `MLpipe_KFold_RMSE`). It would be difficult (but not impossible) to write a general `MLpipe` function that takes a splitter and an evaluation metric also as inputs for two reasons:\n",
    "- some splitters are difficult to pass as a function argument (e.g., two train_test_split steps, or a train_test_split combined with a KFold),\n",
    "- some evaluation metrics need to be maximized (like accuracy, R2, f_beta), while others need to be minimized (like logloss, RMSE) and the code for these two options differ.\n",
    "\n",
    "For now, I recommend that if you need to try multiple ML algorithms, write a function that's specific to a splitting strategy and an evaluation metric and add a description to the function as shown in MLpipe_KFold_RMSE. Such functions make it very easy to try many ML algorithms on your dataset and I recommend you write a similar function for your project.\n",
    "\n",
    "Add plenty of test and print statements to make sure your code works correctly and it does what you expect it to do. You are encouraged to: print the sets and their shapes before and after preprocessing, print the GridSearchCV results, print the test scores, and more.\n",
    "\n",
    "Test the function with linear regression models that use l1 regularization. Fix any warnings you might encounter. Print out the mean and the standard deviation of the test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset as a dataframe\n",
    "df = pd.read_csv(\"https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\", sep='\\t')\n",
    "\n",
    "# create target series and feature matrix \n",
    "y = df['Y']\n",
    "X = df.loc[:, df.columns != 'Y']\n",
    "\n",
    "# function for the ML pipeline as outlined above \n",
    "def MLpipe_KFold_RMSE(X, y, preprocessor, ML_algo, param_grid):\n",
    "    '''\n",
    "    This function splits the data to other/test (80/20) and then applies KFold with 4 folds to other.\n",
    "    The RMSE is minimized in cross-validation.\n",
    "\n",
    "    You should:\n",
    "\n",
    "    1. Loop through 10 different random states\n",
    "    2. Split your data \n",
    "    3. Fit a model using GridSearchCV with KFold and the predefined Preprocessor \n",
    "    4. Calculate the model's error on the test set \n",
    "    5. Return a list of 10 test scores and 10 best models \n",
    "    '''\n",
    "    \n",
    "    # lists to be returned \n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "\n",
    "    # your code here...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return test_scores, best_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your function with a linear regression model (l1 regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2b (15 points)\n",
    "\n",
    "Next, train the following models on the diabetes dataset:\n",
    "- linear regression with l1 regularization (already completed in 2a)\n",
    "- linear regression with l2 regularization \n",
    "- linear regression with an elastic net \n",
    "- RF\n",
    "- SVR\n",
    "- k nearest neighbor regression\n",
    "\n",
    "Please determine what the parameter grid should be for each of these methods. Follow the guidance we discussed during the lecture.\n",
    "\n",
    "Make sure your code is reproducable! When you rerun it, you should get back the exact same test scores and best hyperparameters in each run. So fix your random states where ever necessary.\n",
    "\n",
    "Which algorithm is the best on the diabetes dataset based on the mean and standard deviation of the test scores? Write a paragraph or two and describe your findings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your explanation here**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
